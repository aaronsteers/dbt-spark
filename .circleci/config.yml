version: 2
jobs:
  unit:
    docker:
      - image: fishtownjacob/test-container
    steps:
      - checkout
      - run: tox -e flake8,unit

  integration:
    docker:
      - image: fishtownjacob/test-container
    steps:
      - checkout

      - run:
          name: Checkout test project
          command: git clone --branch spark-support https://github.com/fishtown-analytics/dbt-integration-tests.git

      - run:
          name: Run integration tests
          command: tox -e integration
          no_output_timeout: 1h
          environment:
              DBT_PROFILES_DIR: /home/dbt_test_user/project/test/integration/

      - store_artifacts:
          path: ./logs

  pypi:
    only:
      - master
    docker:
      - image: python:3.7
     steps:
      - checkout

      - run:
          name: Publish to PyPi
          command: |
            echo -e "TODO: Need to set env variables VERSION, PYPI_USER, and PYPI_PASS"
            echo -e "Installing twine...\n\n"
            pip install twine
            echo -e "\nCreating setup package...\n\n"
            python setup.py sdist
            echo -e "\nPublishing to version ref '$VERSION'...\n\n"
            twine upload -u $PYPI_USER -p $PYPI_PASS dist/*

      - run: 
          name: Test install (pip install slalom.dataops)
          command: |
            pip install dbt-spark


workflows:
  version: 2
  test-everything:
    jobs:
      - unit
      - integration:
          requires:
            - unit

  pypi-publish:
    jobs:
      - pypi
 
